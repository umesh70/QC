{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shannon Entropy \n",
    "\n",
    "- In Simpler terms, the shannon entropy can be used to measure the uncertainity of a system. It does so by taking the base 2 logarithm of the probability of a given message occuring.\n",
    "\n",
    "    $$I = -\\log_2 p$$\n",
    "\n",
    "\n",
    "- If a message has a very high probability of occurrence, then we don’t gain all that much new information when we come across it. On the other hand, if a message has a low probability of occurrence, when we are made of aware of it, we gain a significant amount of information.\n",
    "- for example lets say the probability of raining tomorrow is **0.08** and the probability of not raining tomorrow is **0.92.**.\n",
    "\n",
    "- Now as per shannon entropy \n",
    " $$I = -\\log_2 0.08 = 3.644$$\n",
    "$$I' = -\\log_2 0.92 = 0.1203$$\n",
    "\n",
    "- Now by above example we can draw the following conclusions\n",
    "-  A message that is unlikely to occur has a low probability and therefore has a large information content\n",
    "-  A message that is very likely to occur has a high probability and therefore\n",
    "has a small information content.\n",
    "\n",
    "- We can now move onto why or how we can say shannon entropy is used to quantify uncertainity.\n",
    "- Suppose we have a signal that always transmitw a \"2\", the signal looks like a string of **22222222....** , and by definition the probability of 2 is 1.\n",
    "then the entropy is \n",
    "$$I = -\\log_2 1 = 0$$\n",
    "- And since there is no change in signal or disorder the entropy is 0.\n",
    "- We can summarize Shannon entropy as \n",
    "    - Decrease uncertainty ⇒ Increase information\n",
    "    - Increase uncertainty ⇒ Increase entropy\n",
    "- formally, Shannon entropy can be defined as\n",
    "\n",
    "- $$H(X) = -\\sum_{i} p_i \\log_2 p_i$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Entropy \n",
    "- $$H(X|Y) = -\\sum_j p(x_j|y_i) \\log_2(p(x_j|y_i))$$\n",
    "\n",
    "- This is conditional entropy of two variables **X** and **Y** with probability distributions **$p$** and **$y_i$** is a fixed value from **Y**.\n",
    "- It measures how much uncertainity remains about X when we already know some variable Y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qubit\n",
    "\n",
    "- A qubit is a quantum version of the classical binary bit. A classical bit can either be 0 or 1, whereas a Qubit can exist in states analogous to both 0 and 1.\n",
    "\n",
    "- A qubit is a two state quantum mechanical system, meaning a qubit can exist in two distinct states simultaneously,which is not possible in classical bits, it is represented by a linear superposition of its two basis vectors ( ∣0⟩ , ∣1⟩ ).\n",
    "\n",
    "- - $ψ$ = $α∣0⟩+β∣1⟩$\n",
    "- here ( ∣0⟩ , ∣1⟩ ) are represented by\n",
    "- $|0\\rangle = \\begin{bmatrix} 1 \\\\ 0  \\end{bmatrix}$\n",
    "- $|1\\rangle = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$\n",
    "\n",
    "- **𝛼** and **𝛽** are complex coefficients that determine the probability amplitudes of the qubit being in each of the two states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column vector notation of a qubit\n",
    "- $$|\\psi\\rangle = \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix} = \\begin{pmatrix} \\alpha \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ \\beta \\end{pmatrix} = \\alpha \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + \\beta \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$$\n",
    "## Basis \n",
    "- A basis of a vector space is a set of vectors that satifies the following constraints\n",
    "- **Linearly Independent** -> No vector in the **set** can be written as a linear combination of the other vectors in the set.\n",
    "\n",
    "- **Spanning** -> Any vector in the **vector space** can be written as  linear combination of the vectors in the set.\n",
    "- for example, Lego bricks can be said as basis. Each lego brick has a unique shape that you cant make by combining other magic bricks, but these bricks can be used to build any toy or sculpure you want.\n",
    "\n",
    "- A quantum state $|ψ\\rangle$\tcan be written as a linear combination of a basis set $|v_i\\rangle$\twith complex coefficients of expansion $c_i$ as:\n",
    "\n",
    " - $$|\\psi\\rangle = \\sum_{i=1}^n c_i|v_i\\rangle = c_1|v_1\\rangle + c_2|v_2\\rangle + \\cdots + c_n|v_n\\rangle$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inner product\n",
    "- The inner product between two vectors is calculated by,\n",
    "\n",
    "$$\\langle u|v\\rangle$$\n",
    "\n",
    "- If the inner product btw u and v is 0, then the given vectors are orthogonal to one another.\n",
    "\n",
    "- Conjugate of the inner product satifies the following equality.\n",
    "\n",
    "- $$(\\langle u|v \\rangle)^\\dagger = \\langle u|v \\rangle$$\n",
    "\n",
    "- The length of any given vector can be calculated using the root of the inner of product of the vector with itself.This is also known as norm of the vector.\n",
    "\n",
    "- $$||u|| = \\sqrt{ \\langle u|u \\rangle}$$\n",
    "\n",
    " ## Hermitian conjugate\n",
    "\n",
    "- It is the result of taking the complex conjugate of each element in a matrix and then transposing the resulting matrix.\n",
    "\n",
    "- In quantum computing, the Hermitian conjugate is a row vector of conjugates of ket vector.\n",
    "\n",
    "- $$(|v\\rangle)^* = \\langle v|$$ \n",
    "\n",
    "- This conjugation is known as bra vector.\n",
    "\n",
    "- Now we can calculate inner product by,\n",
    "\n",
    "- $$\\langle a|b\\rangle = \\begin{pmatrix} a_1^* & a_2^* & \\cdots & a_n^* \\end{pmatrix} \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_n \\end{pmatrix} = a_1^*b_1 + a_2^*b_2 + \\cdots + a_n^*b_n = \\sum_{i=1}^n a_i^*b_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization \n",
    "- when the length(**norm**) of the vector is unit, then the vector is normalized.That is,\n",
    "$$\\langle u|u\\rangle = 1$$\n",
    "- To normalize a vector we can do so by following.\n",
    "- $$|\\tilde{u} \\rangle = \\frac{|u\\rangle}{{\\|u\\|}}$$\n",
    "- if each element of a set of vectors is normalized and the elements are orthogonal (**inner product is 0**) with respect to each other, we say the set is orthonormal.\n",
    "\n",
    "- In simpler terms, two vectors which are both perpendicular and have a length of one, these vectors are called orthonormal vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
